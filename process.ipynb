{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/raid/home/stea/.conda/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for folders in /cluster/raid/home/stea/ICLR2025/results/HumanEval/default/results with dtype=default.\n",
      "Model:  code-llama-34B-instruct\n",
      "Model:  star-coder-plus\n",
      "Model:  star-chat-beta\n",
      "Model:  codegen25-7B\n",
      "Model:  codegen25-7B-instruct\n",
      "Model:  vicuna-7B\n",
      "Model:  star-coder-base\n",
      "Model:  code-llama-13B-instruct\n",
      "Model:  star-chat-alpha\n",
      "Model:  qwen2.5-coder-32B-Instruct\n",
      "Model:  codegen2-16B\n",
      "Model:  code-llama-7B-instruct\n",
      "Model:  star-coder\n",
      "Model:  codegen2-1B\n",
      "Model:  deepseek-coder-33B-instruct\n",
      "Model:  codegen2-3.7B\n",
      "Model:  codegemma-7B-instruct\n",
      "Model:  llama2-70B-chat\n",
      "Model:  llama2-13B-chat\n",
      "Model:  codegen2-7B\n",
      "Model:  llama2-7B-chat\n",
      "Model:  vicuna-13B\n",
      "Looking for folders in /cluster/raid/home/stea/ICLR2025/results/HumanEval/generation/results with dtype=default.\n",
      "Model:  codegemma-7B\n",
      "Model:  codegemma-7B-instruct\n",
      "Model:  llama2-7B\n",
      "Model:  opt-30B\n",
      "Model:  gpt-neo-125M\n",
      "Model:  codegen2-1B\n",
      "Model:  gpt-j-6B\n",
      "Model:  gpt-neo-2.7B\n",
      "Model:  code-llama-13B\n",
      "Model:  bloom-176B\n",
      "Model:  code-llama-34B-instruct\n",
      "Model:  codegen-350M\n",
      "Model:  star-coder-plus\n",
      "Model:  gpt-neoX-20B\n",
      "Model:  code-llama-13B-instruct\n",
      "Model:  code-llama-7B-python\n",
      "Model:  llama2-7B-chat\n",
      "Model:  codegen-6B\n",
      "Model:  gpt2-xl\n",
      "Model:  code-llama-34B\n",
      "Model:  code-llama-13B-python\n",
      "Model:  code-llama-34B-python\n",
      "Model:  codegen2-16B\n",
      "Model:  stable-lm-7B\n",
      "Model:  opt-1.3B\n",
      "Model:  codegen2-7B\n",
      "Model:  star-coder-base\n",
      "Model:  opt-13B\n",
      "Model:  opt-350M\n",
      "Model:  codegen-2B\n",
      "Model:  vicuna-13B\n",
      "Model:  codegen25-7B-instruct\n",
      "Model:  opt-125M\n",
      "Model:  opt-2.7B\n",
      "Model:  codegen-16B\n",
      "Model:  code-llama-7B\n",
      "Model:  star-chat-alpha\n",
      "Model:  opt-66B\n",
      "Model:  star-chat-beta\n",
      "Model:  gpt2-medium\n",
      "Model:  code-llama-7B-instruct\n",
      "Model:  bloom-3B\n",
      "Model:  stable-lm-3B\n",
      "Model:  llama2-70B\n",
      "Model:  codegen25-7B\n",
      "Model:  llama2-13B\n",
      "Model:  star-coder\n",
      "Model:  deepseek-coder-33B-instruct\n",
      "Model:  qwen2.5-coder-32B-Instruct\n",
      "Model:  bloom-560M\n",
      "Model:  bloom-7.1B\n",
      "Model:  codegen2-3.7B\n",
      "Model:  gpt2-large\n",
      "Model:  qwen2.5-coder-32B\n",
      "Model:  opt-6.7B\n",
      "Model:  bloom-1.7B\n",
      "Model:  gpt-neo-1.3B\n",
      "Model:  llama2-70B-chat\n",
      "Model:  vicuna-7B\n",
      "Model:  llama2-13B-chat\n",
      "Looking for folders in /cluster/raid/home/stea/ICLR2025/results/HumanEvalInstruct/chat_True/results with dtype=default.\n",
      "Model:  codegemma-7B-instruct\n",
      "Model:  qwen2.5-coder-32B-Instruct\n",
      "Model:  deepseek-coder-33B-instruct\n",
      "Looking for folders in /cluster/raid/home/stea/ICLR2025/results/HumanEvalInstruct/default_False/results with dtype=default.\n",
      "Model:  star-coder-plus\n",
      "Model:  code-llama-7B-instruct\n",
      "Model:  codegen2-7B\n",
      "Model:  code-llama-13B-instruct\n",
      "Model:  star-coder\n",
      "Model:  codegen2-3.7B\n",
      "Model:  star-chat-beta\n",
      "Model:  codegen25-7B-instruct\n",
      "Model:  codegen2-1B\n",
      "Model:  star-coder-base\n",
      "Model:  codegen25-7B\n",
      "Model:  code-llama-34B-instruct\n",
      "Model:  vicuna-13B\n",
      "Model:  star-chat-alpha\n",
      "Model:  llama2-70B-chat\n",
      "Model:  vicuna-7B\n",
      "Model:  llama2-13B-chat\n",
      "Model:  llama2-7B-chat\n",
      "Model:  codegen2-16B\n",
      "Looking for folders in /cluster/raid/home/stea/ICLR2025/results/HumanEvalInstruct/generation_False/results with dtype=default.\n",
      "Model:  code-llama-7B-python\n",
      "Model:  gpt2-xl\n",
      "Model:  code-llama-34B-python\n",
      "Model:  opt-6.7B\n",
      "Model:  code-llama-7B\n",
      "Model:  code-llama-13B-python\n",
      "Model:  bloom-7.1B\n",
      "Model:  star-coder\n",
      "Model:  bloom-560M\n",
      "Model:  codegen2-16B\n",
      "Model:  stable-lm-7B\n",
      "Model:  llama2-13B\n",
      "Model:  bloom-1.7B\n",
      "Model:  gpt-neoX-20B\n",
      "Model:  code-llama-13B-instruct\n",
      "Model:  star-coder-base\n",
      "Model:  star-chat-beta\n",
      "Model:  gpt2-large\n",
      "Model:  gpt2-medium\n",
      "Model:  code-llama-7B-instruct\n",
      "Model:  code-llama-34B-instruct\n",
      "Model:  codegen-2B\n",
      "Model:  codegen2-3.7B\n",
      "Model:  vicuna-13B\n",
      "Model:  codegen-350M\n",
      "Model:  bloom-3B\n",
      "Model:  opt-30B\n",
      "Model:  llama2-70B\n",
      "Model:  opt-350M\n",
      "Model:  opt-2.7B\n",
      "Model:  star-coder-plus\n",
      "Model:  codegen-16B\n",
      "Model:  opt-125M\n",
      "Model:  llama2-7B\n",
      "Model:  gpt-neo-125M\n",
      "Model:  gpt-neo-2.7B\n",
      "Model:  vicuna-7B\n",
      "Model:  codegen-6B\n",
      "Model:  codegen2-7B\n",
      "Model:  opt-1.3B\n",
      "Model:  gpt-neo-1.3B\n",
      "Model:  codegen25-7B\n",
      "Model:  llama2-13B-chat\n",
      "Model:  code-llama-13B\n",
      "Model:  llama2-70B-chat\n",
      "Model:  llama2-7B-chat\n",
      "Model:  opt-13B\n",
      "Model:  stable-lm-3B\n",
      "Model:  star-chat-alpha\n",
      "Model:  code-llama-34B\n",
      "Model:  opt-66B\n",
      "Model:  codegen2-1B\n",
      "Model:  gpt-j-6B\n",
      "Model:  codegen25-7B-instruct\n",
      "Model:  bloom-176B\n",
      "Looking for folders in /cluster/raid/home/stea/ICLR2025/results/HumanEvalInstruct/default_True/results with dtype=default.\n",
      "Model:  codegen2-7B\n",
      "Model:  codegen2-3.7B\n",
      "Model:  star-chat-beta\n",
      "Model:  star-chat-alpha\n",
      "Model:  vicuna-7B\n",
      "Model:  codegen2-1B\n",
      "Model:  code-llama-7B-instruct\n",
      "Model:  llama2-13B-chat\n",
      "Model:  llama2-70B-chat\n",
      "Model:  codegen25-7B\n",
      "Model:  star-coder\n",
      "Model:  code-llama-34B-instruct\n",
      "Model:  star-coder-plus\n",
      "Model:  codegen25-7B-instruct\n",
      "Model:  codegen2-16B\n",
      "Model:  code-llama-13B-instruct\n",
      "Model:  llama2-7B-chat\n",
      "Model:  vicuna-13B\n",
      "Model:  star-coder-base\n",
      "Looking for folders in /cluster/raid/home/stea/ICLR2025/results/HumanEvalPHP/generation/results with dtype=default.\n",
      "Model:  codegen25-7B-instruct\n",
      "Model:  code-llama-34B\n",
      "Model:  codegen25-7B\n",
      "Model:  code-llama-34B-instruct\n",
      "Model:  star-coder-base\n",
      "Model:  codegen-16B\n",
      "Model:  star-chat-alpha\n",
      "Model:  llama2-70B\n",
      "Model:  star-coder\n",
      "Model:  code-llama-34B-python\n",
      "Model:  llama2-70B-chat\n",
      "Looking for folders in /cluster/raid/home/stea/ICLR2025/results/HumanEvalCPP/generation/results with dtype=default.\n",
      "Model:  llama2-70B-chat\n",
      "Model:  codegen25-7B-instruct\n",
      "Model:  star-chat-alpha\n",
      "Model:  star-coder-base\n",
      "Model:  code-llama-34B\n",
      "Model:  star-coder\n",
      "Model:  codegen-16B\n",
      "Model:  codegen25-7B\n",
      "Model:  llama2-70B\n",
      "Model:  code-llama-34B-python\n",
      "Model:  code-llama-34B-instruct\n",
      "Looking for folders in /cluster/raid/home/stea/ICLR2025/results/HumanEvalRust/generation/results with dtype=default.\n",
      "Model:  code-llama-34B-python\n",
      "Model:  llama2-70B\n",
      "Model:  star-chat-alpha\n",
      "Model:  codegen25-7B\n",
      "Model:  star-coder\n",
      "Model:  llama2-70B-chat\n",
      "Model:  code-llama-34B\n",
      "Model:  codegen-16B\n",
      "Model:  star-coder-base\n",
      "Model:  code-llama-34B-instruct\n",
      "Model:  codegen25-7B-instruct\n"
     ]
    }
   ],
   "source": [
    "from helpers import humaneval\n",
    "from pathlib import Path\n",
    "\n",
    "models = ['code-gemma-7B', 'code-gemma-7B-instruct', 'deepseek-coder-33B-instruct',\n",
    "    'qwen2.5-coder-32B-instruct', 'qwen2.5-coder-32B',\n",
    "]\n",
    "models_instruct = [\n",
    "    'code-gemma-7B-instruct', 'deepseek-coder-33B-instruct',\n",
    "    'qwen2.5-coder-32B-instruct',\n",
    "]\n",
    "result_path_generation = Path('/cluster/raid/home/stea/ICLR2025/results/HumanEval/generation/results')\n",
    "result_path_instruct = Path('/cluster/raid/home/stea/ICLR2025/results/HumanEval/default/results')\n",
    "\n",
    "# evaluate default models\n",
    "\n",
    "df = humaneval.model_wise_pass_at_k()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">HumanEval</th>\n",
       "      <th>HumanEvalCPP</th>\n",
       "      <th colspan=\"4\" halign=\"left\">HumanEvalInstruct</th>\n",
       "      <th>HumanEvalPHP</th>\n",
       "      <th>HumanEvalRust</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>generation</th>\n",
       "      <th>default</th>\n",
       "      <th>generation</th>\n",
       "      <th>generation_False</th>\n",
       "      <th>default_False</th>\n",
       "      <th>default_True</th>\n",
       "      <th>chat_True</th>\n",
       "      <th>generation</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bloom-560M</th>\n",
       "      <td>1.219512</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bloom-1.7B</th>\n",
       "      <td>4.878049</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bloom-3B</th>\n",
       "      <td>7.317073</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bloom-7.1B</th>\n",
       "      <td>8.536585</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bloom-176B</th>\n",
       "      <td>15.853659</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-7B</th>\n",
       "      <td>29.268293</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>23.780488</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-7B-instruct</th>\n",
       "      <td>29.268293</td>\n",
       "      <td>29.268293</td>\n",
       "      <td>-</td>\n",
       "      <td>34.146341</td>\n",
       "      <td>37.195122</td>\n",
       "      <td>36.585366</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-7B-python</th>\n",
       "      <td>40.853659</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>32.317073</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-13B</th>\n",
       "      <td>34.756098</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>29.878049</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-13B-instruct</th>\n",
       "      <td>39.634146</td>\n",
       "      <td>37.195122</td>\n",
       "      <td>-</td>\n",
       "      <td>36.585366</td>\n",
       "      <td>39.02439</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-13B-python</th>\n",
       "      <td>44.512195</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>25.609756</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-34B</th>\n",
       "      <td>48.780488</td>\n",
       "      <td>-</td>\n",
       "      <td>50.931677</td>\n",
       "      <td>46.95122</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>40.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-34B-instruct</th>\n",
       "      <td>43.292683</td>\n",
       "      <td>39.634146</td>\n",
       "      <td>45.962733</td>\n",
       "      <td>41.463415</td>\n",
       "      <td>47.560976</td>\n",
       "      <td>46.341463</td>\n",
       "      <td>-</td>\n",
       "      <td>39.751553</td>\n",
       "      <td>39.74359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-34B-python</th>\n",
       "      <td>56.097561</td>\n",
       "      <td>-</td>\n",
       "      <td>40.372671</td>\n",
       "      <td>25.609756</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>39.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegemma-7B</th>\n",
       "      <td>42.682927</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegemma-7B-instruct</th>\n",
       "      <td>51.219512</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>27.439024</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen-350M</th>\n",
       "      <td>14.024390</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>9.756098</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen-2B</th>\n",
       "      <td>23.780488</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>22.560976</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen-6B</th>\n",
       "      <td>26.829268</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>25.609756</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen-16B</th>\n",
       "      <td>32.926829</td>\n",
       "      <td>-</td>\n",
       "      <td>13.664596</td>\n",
       "      <td>23.170732</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>9.937888</td>\n",
       "      <td>2.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen2-1B</th>\n",
       "      <td>9.756098</td>\n",
       "      <td>3.658537</td>\n",
       "      <td>-</td>\n",
       "      <td>1.829268</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen2-3.7B</th>\n",
       "      <td>15.853659</td>\n",
       "      <td>9.146341</td>\n",
       "      <td>-</td>\n",
       "      <td>9.146341</td>\n",
       "      <td>3.658537</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen2-7B</th>\n",
       "      <td>20.121951</td>\n",
       "      <td>10.365854</td>\n",
       "      <td>-</td>\n",
       "      <td>11.585366</td>\n",
       "      <td>11.585366</td>\n",
       "      <td>8.536585</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen2-16B</th>\n",
       "      <td>23.170732</td>\n",
       "      <td>10.365854</td>\n",
       "      <td>-</td>\n",
       "      <td>9.756098</td>\n",
       "      <td>8.536585</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen25-7B</th>\n",
       "      <td>31.707317</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>19.875776</td>\n",
       "      <td>17.682927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.292683</td>\n",
       "      <td>-</td>\n",
       "      <td>18.63354</td>\n",
       "      <td>9.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen25-7B-instruct</th>\n",
       "      <td>37.804878</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>24.84472</td>\n",
       "      <td>30.487805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.243902</td>\n",
       "      <td>-</td>\n",
       "      <td>23.602484</td>\n",
       "      <td>7.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-coder-33B-instruct</th>\n",
       "      <td>69.512195</td>\n",
       "      <td>75.609756</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>69.512195</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-j-6B</th>\n",
       "      <td>9.756098</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-neo-125M</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-neo-1.3B</th>\n",
       "      <td>4.878049</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-neo-2.7B</th>\n",
       "      <td>7.317073</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-neoX-20B</th>\n",
       "      <td>15.243902</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2-7B</th>\n",
       "      <td>12.195122</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>4.878049</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2-7B-chat</th>\n",
       "      <td>11.585366</td>\n",
       "      <td>7.317073</td>\n",
       "      <td>-</td>\n",
       "      <td>10.365854</td>\n",
       "      <td>12.804878</td>\n",
       "      <td>10.365854</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2-13B</th>\n",
       "      <td>17.073171</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>12.804878</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2-13B-chat</th>\n",
       "      <td>18.292683</td>\n",
       "      <td>4.878049</td>\n",
       "      <td>-</td>\n",
       "      <td>9.146341</td>\n",
       "      <td>17.073171</td>\n",
       "      <td>11.585366</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2-70B</th>\n",
       "      <td>27.439024</td>\n",
       "      <td>-</td>\n",
       "      <td>29.813665</td>\n",
       "      <td>21.95122</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>32.298137</td>\n",
       "      <td>25.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2-70B-chat</th>\n",
       "      <td>28.048780</td>\n",
       "      <td>18.902439</td>\n",
       "      <td>23.602484</td>\n",
       "      <td>7.926829</td>\n",
       "      <td>29.878049</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-</td>\n",
       "      <td>21.73913</td>\n",
       "      <td>14.74359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-125M</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-350M</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-1.3B</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-2.7B</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-6.7B</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-13B</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-30B</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt-66B</th>\n",
       "      <td>1.219512</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen2.5-coder-32B</th>\n",
       "      <td>61.585366</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen2.5-coder-32B-Instruct</th>\n",
       "      <td>86.585366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stable-lm-3B</th>\n",
       "      <td>0.609756</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stable-lm-7B</th>\n",
       "      <td>3.048780</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-chat-alpha</th>\n",
       "      <td>35.975610</td>\n",
       "      <td>34.756098</td>\n",
       "      <td>36.024845</td>\n",
       "      <td>29.268293</td>\n",
       "      <td>29.878049</td>\n",
       "      <td>42.073171</td>\n",
       "      <td>-</td>\n",
       "      <td>32.298137</td>\n",
       "      <td>23.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-chat-beta</th>\n",
       "      <td>27.439024</td>\n",
       "      <td>23.170732</td>\n",
       "      <td>-</td>\n",
       "      <td>26.829268</td>\n",
       "      <td>26.219512</td>\n",
       "      <td>28.658537</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-coder</th>\n",
       "      <td>34.756098</td>\n",
       "      <td>33.536585</td>\n",
       "      <td>32.298137</td>\n",
       "      <td>32.926829</td>\n",
       "      <td>29.878049</td>\n",
       "      <td>25.609756</td>\n",
       "      <td>-</td>\n",
       "      <td>27.329193</td>\n",
       "      <td>21.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-coder-base</th>\n",
       "      <td>32.926829</td>\n",
       "      <td>26.219512</td>\n",
       "      <td>29.813665</td>\n",
       "      <td>28.04878</td>\n",
       "      <td>29.878049</td>\n",
       "      <td>28.658537</td>\n",
       "      <td>-</td>\n",
       "      <td>26.086957</td>\n",
       "      <td>23.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-coder-plus</th>\n",
       "      <td>26.219512</td>\n",
       "      <td>25.609756</td>\n",
       "      <td>-</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>22.560976</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna-7B</th>\n",
       "      <td>9.756098</td>\n",
       "      <td>1.829268</td>\n",
       "      <td>-</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>10.97561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna-13B</th>\n",
       "      <td>15.243902</td>\n",
       "      <td>6.707317</td>\n",
       "      <td>-</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>17.073171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             HumanEval            HumanEvalCPP  \\\n",
       "                            generation    default   generation   \n",
       "model                                                            \n",
       "bloom-560M                    1.219512          -            -   \n",
       "bloom-1.7B                    4.878049          -            -   \n",
       "bloom-3B                      7.317073          -            -   \n",
       "bloom-7.1B                    8.536585          -            -   \n",
       "bloom-176B                   15.853659          -            -   \n",
       "code-llama-7B                29.268293          -            -   \n",
       "code-llama-7B-instruct       29.268293  29.268293            -   \n",
       "code-llama-7B-python         40.853659          -            -   \n",
       "code-llama-13B               34.756098          -            -   \n",
       "code-llama-13B-instruct      39.634146  37.195122            -   \n",
       "code-llama-13B-python        44.512195          -            -   \n",
       "code-llama-34B               48.780488          -    50.931677   \n",
       "code-llama-34B-instruct      43.292683  39.634146    45.962733   \n",
       "code-llama-34B-python        56.097561          -    40.372671   \n",
       "codegemma-7B                 42.682927          -            -   \n",
       "codegemma-7B-instruct        51.219512          -            -   \n",
       "codegen-350M                 14.024390          -            -   \n",
       "codegen-2B                   23.780488          -            -   \n",
       "codegen-6B                   26.829268          -            -   \n",
       "codegen-16B                  32.926829          -    13.664596   \n",
       "codegen2-1B                   9.756098   3.658537            -   \n",
       "codegen2-3.7B                15.853659   9.146341            -   \n",
       "codegen2-7B                  20.121951  10.365854            -   \n",
       "codegen2-16B                 23.170732  10.365854            -   \n",
       "codegen25-7B                 31.707317   0.609756    19.875776   \n",
       "codegen25-7B-instruct        37.804878   2.439024     24.84472   \n",
       "deepseek-coder-33B-instruct  69.512195  75.609756            -   \n",
       "gpt-j-6B                      9.756098          -            -   \n",
       "gpt-neo-125M                  0.000000          -            -   \n",
       "gpt-neo-1.3B                  4.878049          -            -   \n",
       "gpt-neo-2.7B                  7.317073          -            -   \n",
       "gpt-neoX-20B                 15.243902          -            -   \n",
       "gpt2-medium                   0.000000          -            -   \n",
       "gpt2-large                    0.000000          -            -   \n",
       "gpt2-xl                       0.000000          -            -   \n",
       "llama2-7B                    12.195122          -            -   \n",
       "llama2-7B-chat               11.585366   7.317073            -   \n",
       "llama2-13B                   17.073171          -            -   \n",
       "llama2-13B-chat              18.292683   4.878049            -   \n",
       "llama2-70B                   27.439024          -    29.813665   \n",
       "llama2-70B-chat              28.048780  18.902439    23.602484   \n",
       "opt-125M                      0.000000          -            -   \n",
       "opt-350M                      0.000000          -            -   \n",
       "opt-1.3B                      0.000000          -            -   \n",
       "opt-2.7B                      0.000000          -            -   \n",
       "opt-6.7B                      0.000000          -            -   \n",
       "opt-13B                       0.000000          -            -   \n",
       "opt-30B                       0.000000          -            -   \n",
       "opt-66B                       1.219512          -            -   \n",
       "qwen2.5-coder-32B            61.585366          -            -   \n",
       "qwen2.5-coder-32B-Instruct   86.585366        0.0            -   \n",
       "stable-lm-3B                  0.609756          -            -   \n",
       "stable-lm-7B                  3.048780          -            -   \n",
       "star-chat-alpha              35.975610  34.756098    36.024845   \n",
       "star-chat-beta               27.439024  23.170732            -   \n",
       "star-coder                   34.756098  33.536585    32.298137   \n",
       "star-coder-base              32.926829  26.219512    29.813665   \n",
       "star-coder-plus              26.219512  25.609756            -   \n",
       "vicuna-7B                     9.756098   1.829268            -   \n",
       "vicuna-13B                   15.243902   6.707317            -   \n",
       "\n",
       "                            HumanEvalInstruct                             \\\n",
       "                             generation_False default_False default_True   \n",
       "model                                                                      \n",
       "bloom-560M                                0.0             -            -   \n",
       "bloom-1.7B                           0.609756             -            -   \n",
       "bloom-3B                             0.609756             -            -   \n",
       "bloom-7.1B                                0.0             -            -   \n",
       "bloom-176B                                0.0             -            -   \n",
       "code-llama-7B                       23.780488             -            -   \n",
       "code-llama-7B-instruct              34.146341     37.195122    36.585366   \n",
       "code-llama-7B-python                32.317073             -            -   \n",
       "code-llama-13B                      29.878049             -            -   \n",
       "code-llama-13B-instruct             36.585366      39.02439         50.0   \n",
       "code-llama-13B-python               25.609756             -            -   \n",
       "code-llama-34B                       46.95122             -            -   \n",
       "code-llama-34B-instruct             41.463415     47.560976    46.341463   \n",
       "code-llama-34B-python               25.609756             -            -   \n",
       "codegemma-7B                                -             -            -   \n",
       "codegemma-7B-instruct                       -             -            -   \n",
       "codegen-350M                         9.756098             -            -   \n",
       "codegen-2B                          22.560976             -            -   \n",
       "codegen-6B                          25.609756             -            -   \n",
       "codegen-16B                         23.170732             -            -   \n",
       "codegen2-1B                          1.829268      2.439024          0.0   \n",
       "codegen2-3.7B                        9.146341      3.658537     0.609756   \n",
       "codegen2-7B                         11.585366     11.585366     8.536585   \n",
       "codegen2-16B                         9.756098      8.536585     0.609756   \n",
       "codegen25-7B                        17.682927           0.0    18.292683   \n",
       "codegen25-7B-instruct               30.487805           0.0    15.243902   \n",
       "deepseek-coder-33B-instruct                 -             -            -   \n",
       "gpt-j-6B                                  0.0             -            -   \n",
       "gpt-neo-125M                              0.0             -            -   \n",
       "gpt-neo-1.3B                              0.0             -            -   \n",
       "gpt-neo-2.7B                              0.0             -            -   \n",
       "gpt-neoX-20B                              0.0             -            -   \n",
       "gpt2-medium                               0.0             -            -   \n",
       "gpt2-large                                0.0             -            -   \n",
       "gpt2-xl                                   0.0             -            -   \n",
       "llama2-7B                            4.878049             -            -   \n",
       "llama2-7B-chat                      10.365854     12.804878    10.365854   \n",
       "llama2-13B                          12.804878             -            -   \n",
       "llama2-13B-chat                      9.146341     17.073171    11.585366   \n",
       "llama2-70B                           21.95122             -            -   \n",
       "llama2-70B-chat                      7.926829     29.878049         25.0   \n",
       "opt-125M                                  0.0             -            -   \n",
       "opt-350M                                  0.0             -            -   \n",
       "opt-1.3B                                  0.0             -            -   \n",
       "opt-2.7B                                  0.0             -            -   \n",
       "opt-6.7B                                  0.0             -            -   \n",
       "opt-13B                                   0.0             -            -   \n",
       "opt-30B                                   0.0             -            -   \n",
       "opt-66B                                   0.0             -            -   \n",
       "qwen2.5-coder-32B                           -             -            -   \n",
       "qwen2.5-coder-32B-Instruct                  -             -            -   \n",
       "stable-lm-3B                              0.0             -            -   \n",
       "stable-lm-7B                              0.0             -            -   \n",
       "star-chat-alpha                     29.268293     29.878049    42.073171   \n",
       "star-chat-beta                      26.829268     26.219512    28.658537   \n",
       "star-coder                          32.926829     29.878049    25.609756   \n",
       "star-coder-base                      28.04878     29.878049    28.658537   \n",
       "star-coder-plus                      0.609756     22.560976     0.609756   \n",
       "vicuna-7B                            0.609756      10.97561          0.0   \n",
       "vicuna-13B                           2.439024     17.073171          0.0   \n",
       "\n",
       "                                       HumanEvalPHP HumanEvalRust  \n",
       "                             chat_True   generation    generation  \n",
       "model                                                              \n",
       "bloom-560M                           -            -             -  \n",
       "bloom-1.7B                           -            -             -  \n",
       "bloom-3B                             -            -             -  \n",
       "bloom-7.1B                           -            -             -  \n",
       "bloom-176B                           -            -             -  \n",
       "code-llama-7B                        -            -             -  \n",
       "code-llama-7B-instruct               -            -             -  \n",
       "code-llama-7B-python                 -            -             -  \n",
       "code-llama-13B                       -            -             -  \n",
       "code-llama-13B-instruct              -            -             -  \n",
       "code-llama-13B-python                -            -             -  \n",
       "code-llama-34B                       -    42.857143     40.384615  \n",
       "code-llama-34B-instruct              -    39.751553      39.74359  \n",
       "code-llama-34B-python                -    42.857143     39.102564  \n",
       "codegemma-7B                         -            -             -  \n",
       "codegemma-7B-instruct        27.439024            -             -  \n",
       "codegen-350M                         -            -             -  \n",
       "codegen-2B                           -            -             -  \n",
       "codegen-6B                           -            -             -  \n",
       "codegen-16B                          -     9.937888      2.564103  \n",
       "codegen2-1B                          -            -             -  \n",
       "codegen2-3.7B                        -            -             -  \n",
       "codegen2-7B                          -            -             -  \n",
       "codegen2-16B                         -            -             -  \n",
       "codegen25-7B                         -     18.63354      9.615385  \n",
       "codegen25-7B-instruct                -    23.602484      7.692308  \n",
       "deepseek-coder-33B-instruct  69.512195            -             -  \n",
       "gpt-j-6B                             -            -             -  \n",
       "gpt-neo-125M                         -            -             -  \n",
       "gpt-neo-1.3B                         -            -             -  \n",
       "gpt-neo-2.7B                         -            -             -  \n",
       "gpt-neoX-20B                         -            -             -  \n",
       "gpt2-medium                          -            -             -  \n",
       "gpt2-large                           -            -             -  \n",
       "gpt2-xl                              -            -             -  \n",
       "llama2-7B                            -            -             -  \n",
       "llama2-7B-chat                       -            -             -  \n",
       "llama2-13B                           -            -             -  \n",
       "llama2-13B-chat                      -            -             -  \n",
       "llama2-70B                           -    32.298137     25.641026  \n",
       "llama2-70B-chat                      -     21.73913      14.74359  \n",
       "opt-125M                             -            -             -  \n",
       "opt-350M                             -            -             -  \n",
       "opt-1.3B                             -            -             -  \n",
       "opt-2.7B                             -            -             -  \n",
       "opt-6.7B                             -            -             -  \n",
       "opt-13B                              -            -             -  \n",
       "opt-30B                              -            -             -  \n",
       "opt-66B                              -            -             -  \n",
       "qwen2.5-coder-32B                    -            -             -  \n",
       "qwen2.5-coder-32B-Instruct         0.0            -             -  \n",
       "stable-lm-3B                         -            -             -  \n",
       "stable-lm-7B                         -            -             -  \n",
       "star-chat-alpha                      -    32.298137     23.076923  \n",
       "star-chat-beta                       -            -             -  \n",
       "star-coder                           -    27.329193     21.153846  \n",
       "star-coder-base                      -    26.086957     23.076923  \n",
       "star-coder-plus                      -            -             -  \n",
       "vicuna-7B                            -            -             -  \n",
       "vicuna-13B                           -            -             -  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import humaneval, utils\n",
    "\n",
    "df = humaneval.model_wise_pass_at_k(dtype='int8')\n",
    "utils.latex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import humaneval\n",
    "\n",
    "df = humaneval.model_wise_pass_at_k_comparison()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import humaneval\n",
    "# humaneval.model_wise_error_causes(save=False)\n",
    "df = humaneval.model_wise_pass_at_k()\n",
    "df = df[df[('HumanEvalPHP', 'generation')] != '-']\n",
    "utils.latex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import aatk\n",
    "\n",
    "aatk.valid_completions(dataset='AATK_instruct_chatGPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import aatk\n",
    "\n",
    "aatk.vulnerable_completions(dataset='AATK_instruct_chatGPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import aatk, utils\n",
    "\n",
    "df = aatk.prompt_exposure(dataset='AATK_instruct_chatGPT')\n",
    "# df = df[['Command-R',\t'Llama3 8B - Instruct',\t'Llama3 70B - Instruct']]\n",
    "print(utils.latex(df))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import utils, aatk\n",
    "import os\n",
    "dataset = 'AATK_instruct_chatGPT'\n",
    "model = dataset.split('_')[-1]\n",
    "filename = os.path.join(utils.ROOT_FOLDER, 'plots', f'distribution_{model}.pdf')\n",
    "# aatk.probability_distributions(dataset, filename=filename)\n",
    "aatk.probability_distributions(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aatk.model_exposure(dataset='AATK_instruct_chatGPT', exponential_average=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import aatk\n",
    "\n",
    "aatk.valid_completions(dataset='AATK_instruct_chatGPT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
